{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import category_encoders as ce"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Don't forget to change it for your computer. Use the 'clean' verion (from Ridha's Notebook)\n",
    "path_to_clean_data_SA = '../../../ML_EBOLA/Cleaned_data/SA_clean/SA_clean.csv'\n",
    "path_to_clean_data_DD = '../../../ML_EBOLA/Cleaned_data/DD_clean.csv'\n",
    "path_to_clean_data_DM = '../../../ML_EBOLA/Cleaned_data/DM_clean.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_SA = pd.read_csv('../../../ML_EBOLA/Cleaned_data/SA_clean/SA_clean.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Categorical data in SA\n",
    "We replace the categorical features such as symptoms by each symptom having one column and then 0 or 1 for postiive\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_SA.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_SA['SAMODIFY'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum(df_SA['SAMODIFY'].isna())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# You need to import : import category_encoders as ce (pip install)\n",
    "name = ce.OneHotEncoder(handle_unknown='ignore', use_cat_names=True)\n",
    "\n",
    "# Then you fit the column which you wish to encode\n",
    "symptoms = name.fit_transform(df_SA['SAMODIFY'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now carefull ! we have transformed also the NaN into an encoding value (see 8-to-last)\n",
    "symptoms.info() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This removes the 9 first letters of the header for each column (removes SAMODIFY_)\n",
    "symptoms.columns = [ x[9:] for x in symptoms.columns ] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This removes the column of NaN's (up for debate)\n",
    "symptoms.drop(columns= 'nan', inplace= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "symptoms # See, happy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I am removing SAMODIFY AND SATERM \n",
    "\n",
    "\"\"\"\n",
    "cols = [5,6]#[0,2]\n",
    "df_SA.drop(df_SA.columns[cols], axis =1, inplace = True)\n",
    "\"\"\"\n",
    "#alternate writing\n",
    "cols = ['SAMODIFY', 'SATERM']\n",
    "df_SA.drop(columns= cols, inplace= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_SA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this is the file were we add the one hot encoding ! \n",
    "df_SA_symp = df_SA.join(symptoms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_SA_symp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we have the symptoms \n",
    "# Let's import the result (EBOLA/OTHER) and also some demographics (age and sex)\n",
    "df_DD = pd.read_csv(path_to_clean_data_DD)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_DM = pd.read_csv(path_to_clean_data_DM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cause of death (We can see this needs to be changed....)\n",
    "# TWO categories, EBOLA vs OTHERS \n",
    "df_DD['DDORRES']\n",
    "\n",
    "def parse_death_causes(cause):\n",
    "    ebola = ['EBOLA', 'DIED EBOLA POSITIVE', 'PROBABLE EBOLA','EVD', 'EBOLA SURVIVOR DIED BEFORE DISCHARGE']\n",
    "    if(cause in ebola):\n",
    "        return \"EBOLA\"\n",
    "    else:\n",
    "        return \"OTHER\"\n",
    "\n",
    "df_DD.loc[:,'DDORRES'] = df_DD['DDORRES'].apply(lambda x: parse_death_causes(x))\n",
    "death_causes_count = df_DD['DDORRES'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_DD['DDORRES'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_DD['USUBJID'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"cols = [0,1,2,9,10]\n",
    "df_DD.drop(df_DD.columns[cols], axis =1, inplace = True)\n",
    "\"\"\"\n",
    "# Alternate writing\n",
    "colsDD = ['Unnamed: 0', 'STUDYID', 'DOMAIN', 'DDSTRTPT', 'DDSTTPT']\n",
    "df_DD.drop(columns= colsDD, inplace= True)\n",
    "# the data set has now, EBOLA OR OTHER :)\n",
    "# Let me just drop many columns \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"colsDM = [0,1,2,6,10,11,12,14]\n",
    "df_DM.drop(df_DM.columns[colsDM], axis =1, inplace = True)\"\"\"\n",
    "colsDM = ['Unnamed: 0', 'STUDYID', 'DOMAIN', 'SITEID', 'ARMCD', 'ARM', 'COUNTRY', 'CITIES']\n",
    "df_DM.drop(columns= colsDM, inplace= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's only look at day one careful not the the same reference day right ..... ?  \n",
    "df_DD1 = df_DD[df_DD['DDDY']==1.0]\n",
    "df_DM1 = df_DM[df_DM['DMDY'] ==1.0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's merge \n",
    "Merged = df_DD1.merge(df_DM1, how = 'inner', on = 'USUBJID')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Merged[\"DDORRES\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Merged['SEX'] = Merged['SEX'].apply(lambda x: 1 if x == 'M' else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This variable is a sequence number to ensure uniqueness of subject records within the domain. Each observation \n",
    "#(each recorded as a separate row in the table) will have a unique number within each subject.\n",
    "Merged = Merged[Merged[\"DDSEQ\"] == 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Questionnable choice... (But I'm in no position to say better)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Merged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Merged.USUBJID.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_Temp = Merged.copy()\n",
    "df_Temp2 = df_Temp[df_Temp['DDORRES'] == \"EBOLA\"]\n",
    "df_Temp2.USUBJID.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_SA_symp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge with symptoms \n",
    "df_ml = Merged.merge(df_SA_symp, how = 'inner', on = 'USUBJID')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "uniqueValues = df_ml['USUBJID'].nunique()\n",
    "print(\"We have \",uniqueValues, \" unique patients\")\n",
    "df_ml[\"DDORRES\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The same person is tagged with ebola mutliple times because we have different symptoms ? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ml.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ml['SASCAT']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"# Drop non_null values \n",
    "df_ml.drop(df_ml.columns[[23,27]], inplace = True, axis = 1)\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Very bruteforce hardfix to drop all NaN...\n",
    "df_ml = df_ml.dropna(axis= 'columns')\n",
    "df_ml.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df_ml[df_ml.duplicated()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ml[\"DDSEQ\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ml.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# All age are in years you can drop AGEUnit\n",
    "df_ml[\"AGEU\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Now I'm bout to drop MANY MANY features (carefull I only kept DDSEQ ==1 for now )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"cols_ml = [\n",
    "    0, # USUBJID : no need for the ID anymore\n",
    "    1, # DDSEQ\n",
    "    2, # DDTEST\n",
    "    3, # DDTESTCD\n",
    "    5, # DDDY\n",
    "    6, # RFSTDTC\n",
    "    7, # DTHFL\n",
    "    9, # AGEU\n",
    "    11,# DMDY\n",
    "    12,# Unnamed: 0\n",
    "    13,# STUDYID\n",
    "    14,# DOMAIN\n",
    "    15,# SASEQ\n",
    "    16,# SACAT\n",
    "    17,# SASCAT\n",
    "    18,# SAPRESP\n",
    "    19,# SAOCCUR  \n",
    "    20,# SASTAT\n",
    "    21,# SAREASND\n",
    "    22,# SASEV\n",
    "    23,# EPOCH \n",
    "    24,# SADY\n",
    "    25 # SASTDY\n",
    "]\n",
    "df_ML = df_ml.drop(df_ml.columns[cols_ml], axis = 1)\"\"\"\n",
    "\n",
    "# Alternative writing:\n",
    "cols = [\n",
    "    'USUBJID',\n",
    "    'DDSEQ',\n",
    "    'DDTEST',\n",
    "    'DDTESTCD',\n",
    "    'DDDY',\n",
    "    'RFSTDTC',\n",
    "    'DTHFL',\n",
    "    'AGEU',\n",
    "    'DMDY',\n",
    "    'Unnamed: 0',\n",
    "    'STUDYID',\n",
    "    'DOMAIN',\n",
    "    'SASEQ',\n",
    "    #'SACAT',\n",
    "    #'SASCAT',\n",
    "    #'SAPRESP',\n",
    "    #'SAOCCUR',\n",
    "    #'SASTAT',\n",
    "    #'SAREASND',\n",
    "    #'SASEV',\n",
    "    #'EPOCH',\n",
    "    #'SADY',\n",
    "    #'SASTDY'\n",
    "]\n",
    "df_ML = df_ml.drop(columns= cols, inplace= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ok so here we are left with EBOLA, other, the symptoms, age and sex \n",
    "df_ml.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try to see which columns are redundant...\n",
    "worry_columns = []\n",
    "for x in df_ml.columns:\n",
    "    if df_ml[x].value_counts().size == 1:  # i.e. if there is only one value in the whole column, it is strange\n",
    "        worry_columns.append(x)\n",
    "        \n",
    "worry_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### !!! Need to see with someone who knows more..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now drop those ~meaningless columns \n",
    "df_ml.drop(columns= worry_columns, inplace= True)\n",
    "\n",
    "df_ml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's try and model\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "\n",
    "#select the features needed\n",
    "df_triage = df_ml\n",
    "\n",
    "#transform the dependent variable\n",
    "dict_fstatus = {'EBOLA' : 1, 'OTHER' : 0}\n",
    "df_triage['DDORRES'] = df_triage['DDORRES'].apply(lambda x : dict_fstatus[x]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_triage['USUBJID'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_temp = df_triage.copy()\n",
    "df_temp = df_temp[df_temp['DDORRES'] == 1]\n",
    "df_temp['USUBJID'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_triage.apply(lambda x: sum(x.isna()),axis=0)\n",
    "df_triage.dropna(how='any',inplace= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#normalize the continuous variables \n",
    "scaler = StandardScaler()\n",
    "df_triage[['AGE']] = scaler.fit_transform(df_triage[['AGE']])\n",
    "df_triage.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "plt.figure(figsize=(12, 8))\n",
    "corr = df_triage.corr()\n",
    "color = plt.get_cmap('coolwarm')\n",
    "color.set_bad('lightgrey') \n",
    "sns.heatmap(corr, xticklabels=corr.columns, yticklabels=corr.columns ,annot=True, fmt=\".2f\", cmap = color)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df_triage = df_triage.loc[:, (df_triage != 0).any(axis=0)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.api as sm\n",
    "\n",
    "X = sm.add_constant(df_triage.loc[:, df_triage.columns != 'DDORRES'])\n",
    "y = df_triage['DDORRES']\n",
    "\n",
    "est_OLS = sm.OLS(y, X.astype(float)).fit()\n",
    "print(est_OLS.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "est_logit = sm.Logit(y, X.astype(float)).fit()\n",
    "print(est_logit.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
