{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lavinia/anaconda3/lib/python3.8/site-packages/IPython/core/interactiveshell.py:3071: DtypeWarning: Columns (6,7,8,12,14,15,16,17,19,20,21,26,28,29,30) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n",
      "/home/lavinia/anaconda3/lib/python3.8/site-packages/IPython/core/interactiveshell.py:3071: DtypeWarning: Columns (7,8,13,18) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n"
     ]
    }
   ],
   "source": [
    "# Importing and dropping columns containing NaN\n",
    "\n",
    "# Death Detail\n",
    "df_DD = pd.read_csv('../Cleaned_data/DD_clean.csv')\n",
    "#df_DD = df_DD.dropna(axis = 1) \n",
    "# Dropping the columns having NaN/NaT values \n",
    "\n",
    "# Demographics data\n",
    "df_DM = pd.read_csv('../Cleaned_data/DM_clean.csv')\n",
    "#df_DM = df_DM.dropna(axis = 1)\n",
    "\n",
    "# Disposition \n",
    "df_DS = pd.read_csv('../Cleaned_data/DS_clean.csv')\n",
    "#df_DS = df_DS.dropna(axis = 1)\n",
    "\n",
    "# Disease response\n",
    "df_IN = pd.read_csv('../Cleaned_data/IN_clean.csv')\n",
    "#df_RS = df_RS.dropna(axis = 1)\n",
    "\n",
    "# Clinical adverse\n",
    "df_SA = pd.read_csv('../Cleaned_data/SA_clean.csv')\n",
    "#df_SA = df_SA.dropna(axis = 1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lab results \n",
    "df_LB = pd.read_csv('../Cleaned_data/LB_clean.csv')\n",
    "\n",
    "# MB microbology or something\n",
    "df_MB = pd.read_csv('../Cleaned_data/MB_clean.csv')\n",
    "\n",
    "# RS (please complete what it stands for)\n",
    "df_RS = pd.read_csv('../Cleaned_data/RS_clean.csv')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# For the merging, files are too big, I thus decided to remove \n",
    "- df_IN: which corresponds to Treatments and Interventions\n",
    "#.merge(df_IN, how = 'inner', on = 'USUBJID')\n",
    "- df_SA : It is extremely important but for very big, we must think how to deal with this\n",
    ".merge(df_SA, how = 'inner', on = 'USUBJID')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# We want to merge using the USUBJID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#merged_inner = pd.merge(left=df_DM, right=df_DD, left_on='USUBJID', right_on='USUBJID')\n",
    "merged_inner = df_DD.merge(df_DM, how = 'inner', on = 'USUBJID').merge(df_DS, how = 'inner', on = 'USUBJID').merge(df_IN, how = 'inner', on = 'USUBJID').merge(df_MB, how = 'inner', on = 'USUBJID').merge(df_RS, how = 'inner', on = 'USUBJID').merge(df_VS, how = 'inner', on = 'USUBJID')\n",
    "merged_inner.shape\n",
    "merged_inner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_inner\n",
    "merged_inner.to_csv(\"merged_inner.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "480\n"
     ]
    }
   ],
   "source": [
    "#How many different people within this, since every person can have many observations\n",
    "# We have 480 people with all features that we wish to observe \n",
    "\n",
    "uniqueValues = merged_inner['USUBJID'].nunique()\n",
    "print(uniqueValues)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
