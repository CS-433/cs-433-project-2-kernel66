{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### First study EIXUZQ\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summary of notebook: \n",
    "\n",
    "This dataset gives the information of the diagnostic (FinalStatus) and the prognostic (TypeOfExit) of each patient. \n",
    "\n",
    "\n",
    "*Data analysis*\n",
    "\n",
    "- First we looked at the patients and we found out that one patient has two records. We assumed that is was another patient (second patient F716 become patient F716_bis)\n",
    "\n",
    "- Then we looked at the distributions of certain characteristics of the patients (age, sex, pregnant, HealthCareWorker, Occupation, County), and at the chronology of the epidemic (distribution of the daily start of illness reported, distribution of the monthly start report, etc). We noticed that there was no information about the pregnancy of the patients (only nans) so we dropped this column. \n",
    "\n",
    "- We computed the time between the start of the illness and the report. This allowed us to detect that a patient was reported before his illness began. So we removed it.\n",
    "\n",
    "- Thanks to the previous calculation of the reference time, we were able to draw the distribution of the number of cases diagnosed according to the reference time. We did the same for the outcome. \n",
    "We were also interested in whether the waiting time before admission to the clinic, and the time spent at the clinic, had an effect on patient outcome. \n",
    "\n",
    "- We finally took a quick look at the contacts of the patients, and at the results of the malaria tests as we are aware that the symptoms are close to those of ebola. \n",
    "\n",
    "\n",
    "*Processing*\n",
    "\n",
    "- For the final choice of dataframe on which we will build our models, we decided to keep only certain information about the patient (sex, age, Referraltime) as well as the outputs (FinalStatus and TypeofExit). \n",
    "\n",
    "- This choice of dataframe is followed by a bit of cleaning to remove the patients with no known symptoms (we drop these rows).\n",
    "\n",
    "- To fill in the missing values, we made the (debatable) assumption that when the symptom is not filled in, it means that the patient does not present this symptom (we fill the Nan with zeros). \n",
    "\n",
    "\n",
    "*Data visualization*\n",
    "\n",
    "- A visualization of the correlation matrix confirms that our features are not overly correlated. \n",
    "\n",
    "- Then we identified the features with the highest correlations with the target value (FinalStatus). \n",
    "\n",
    "- We checked the balance of our dataset and we concluded that our dataset is quite unbalanced and that it will have to be taken into account in the interpretation of the results (especially for accuracy).\n",
    "\n",
    "- Finally, we tried to identify clusters in our data, using a function that shows how strongly each feature influences a principal component (PCA1 or PCA2). But unfortunately no cluster was detected in either two or three dimensions.\n",
    "\n",
    "So we split our data to start with the models, checking that the folds preserve the percentage of samples for both class (stratify attribute).\n",
    "\n",
    "\n",
    "*Models*\n",
    "\n",
    "The list of performed models is as follows:\n",
    "\n",
    "1. Least-squares\n",
    "\n",
    "2. Logistic \n",
    "\n",
    "For both first models we performed backward elimination and then updated the models with the selected features. \n",
    "We also performed recursive feature elimination for linear and logistic regression (ex: for logistic regression the optimum number of features was 11). \n",
    "Finally we tried some Ensemble methods (see the description in the corresponding cell). This gave us the feature importance with a lasso model. \n",
    "\n",
    "3. Decision Trees\n",
    "\n",
    "4. Random Forest \n",
    "\n",
    "For the last two models we have obtained graphic illustrations.\n",
    "\n",
    "Our latest model, XGBoost, is the most complex model in terms of the number of parameters. A description of the model is given in the corresponding cells.  \n",
    "\n",
    "5. XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from proj2_HELPERS_ import *\n",
    "from yellowbrick.model_selection import ValidationCurve\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, StratifiedKFold\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tool to calculate carbon footprint\n",
    "from cumulator import base\n",
    "\n",
    "cumulator = base.Cumulator()\n",
    "cumulator.on()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '../../Cleaned_data/EIXUZQ_LIB_FOYA.xls'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-e6ba48266b20>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Enter path to cleaned data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_excel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'../../Cleaned_data/EIXUZQ_LIB_FOYA.xls'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheader\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/pandas/io/excel/_base.py\u001b[0m in \u001b[0;36mread_excel\u001b[0;34m(io, sheet_name, header, names, index_col, usecols, squeeze, dtype, engine, converters, true_values, false_values, skiprows, nrows, na_values, keep_default_na, verbose, parse_dates, date_parser, thousands, comment, skipfooter, convert_float, mangle_dupe_cols, **kwds)\u001b[0m\n\u001b[1;32m    302\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    303\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mio\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mExcelFile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 304\u001b[0;31m         \u001b[0mio\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mExcelFile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mio\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    305\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    306\u001b[0m         raise ValueError(\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/pandas/io/excel/_base.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, io, engine)\u001b[0m\n\u001b[1;32m    822\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_io\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstringify_path\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mio\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    823\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 824\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engines\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_io\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    825\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    826\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__fspath__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/pandas/io/excel/_xlrd.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, filepath_or_buffer)\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0merr_msg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"Install xlrd >= 1.0.0 for Excel support\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m         \u001b[0mimport_optional_dependency\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"xlrd\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mextra\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merr_msg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/pandas/io/excel/_base.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, filepath_or_buffer)\u001b[0m\n\u001b[1;32m    351\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbook\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_workbook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    352\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 353\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbook\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_workbook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    354\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbytes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    355\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbook\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_workbook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mBytesIO\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/pandas/io/excel/_xlrd.py\u001b[0m in \u001b[0;36mload_workbook\u001b[0;34m(self, filepath_or_buffer)\u001b[0m\n\u001b[1;32m     34\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mopen_workbook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_contents\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mopen_workbook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/xlrd/__init__.py\u001b[0m in \u001b[0;36mopen_workbook\u001b[0;34m(filename, logfile, verbosity, use_mmap, file_contents, encoding_override, formatting_info, on_demand, ragged_rows)\u001b[0m\n\u001b[1;32m    109\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m         \u001b[0mfilename\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpanduser\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 111\u001b[0;31m         \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"rb\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    112\u001b[0m             \u001b[0mpeek\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpeeksz\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mpeek\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34mb\"PK\\x03\\x04\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;31m# a ZIP file\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '../../Cleaned_data/EIXUZQ_LIB_FOYA.xls'"
     ]
    }
   ],
   "source": [
    "# Enter path to cleaned data\n",
    "df = pd.read_excel('../../Cleaned_data/EIXUZQ_LIB_FOYA.xls', header =[1])\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"FinalStatus\"].value_counts(dropna=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.FinalStatus.value_counts(dropna=False).plot(kind='pie',labels=['Confirmed', 'Not a case', 'Probable', 'Nan'], colors=['pink', 'b', 'c', 'r'], fontsize=10, figsize=(6, 6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sns.heatmap(df.isnull(), cbar=False)\n",
    "\n",
    "\n",
    "f, ax = plt.subplots(figsize=(14, 7))\n",
    "ax = sns.heatmap(df.isnull(), cbar=False)\n",
    "ax.set_xticklabels(ax.get_xmajorticklabels(), fontsize = 12)\n",
    "ax.set_yticklabels(ax.get_ymajorticklabels(), fontsize = 0)\n",
    "plt.savefig('Data_distribution_1.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Numero"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum(df['Sex'].isna())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['numero'].nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One numero has 2 records. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['numero'].value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The patient with two records is F716."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df['numero'] == 'F716']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Age']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[849, 'numero'] = 't_bis'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum(df['Sex'].isna())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Sex'].value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_sex = {'m' : 'M', 'f' : 'F'}\n",
    "\n",
    "def correct_sex(row):\n",
    "    if row.Sex in dict_sex:\n",
    "            return dict_sex[row.Sex]\n",
    "    return row.Sex\n",
    "\n",
    "df['Sex'] = df.apply(correct_sex,axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Sex'].value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Age"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum(df['Age'].isna())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Age']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Age'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Age'].median()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Age'].min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Age'].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Age'].value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(5,5))\n",
    "\n",
    "ax.set_title(\"Boxplot of the age\",size=15)\n",
    "plt.boxplot(df.loc[~df['Age'].isna(),'Age'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pregnant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum(~df['Pregnant'].isna())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(columns= ['Pregnant'], inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### HealthCareWorker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['HealthCareWorker'].value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Occupation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum(df['Occupation'].isna())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Occupation'] = df['Occupation'] .str.lower()\n",
    "df['Occupation'].value_counts(dropna=False).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### County"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum(df['County'].isna())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['County'] = df['County'].str.lower()\n",
    "df['County'].value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DateIllnessStarted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum(df['DateIllnessStarted'].isna())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['DateIllnessStarted_day'] = df['DateIllnessStarted'].dt.to_period('D')\n",
    "df['DateIllnessStarted_month'] = df['DateIllnessStarted'].dt.to_period('M')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(20,10))\n",
    "\n",
    "df['DateIllnessStarted_day'].value_counts().sort_index().plot(kind =\"bar\")\n",
    "\n",
    "ax.set_title(\"Distribution of the daily start of illness reported\",size=15)\n",
    "ax.set_xlabel('Day')\n",
    "ax.set_ylabel('Number of case')\n",
    "ax.xaxis.set_major_locator(plt.MaxNLocator(30))\n",
    "plt.xticks(rotation=70)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DateofCaseReport"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum(df['dateofCaseReport'].isna())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['dateofCaseReport_day'] = df['dateofCaseReport'].dt.to_period('D')\n",
    "df['dateofCaseReport_month'] = df['dateofCaseReport'].dt.to_period('M')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(20,10))\n",
    "\n",
    "df['dateofCaseReport_day'].value_counts(dropna=False).sort_index().plot(kind =\"bar\")\n",
    "\n",
    "ax.set_title(\"Distribution of the daily case report\",size=15)\n",
    "ax.set_xlabel('Day')\n",
    "ax.set_ylabel('Number of case report')\n",
    "ax.xaxis.set_major_locator(plt.MaxNLocator(30))\n",
    "plt.xticks(rotation=70)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(20,10))\n",
    "\n",
    "df['dateofCaseReport_month'].value_counts(dropna=False).sort_index().plot(kind =\"bar\")\n",
    "\n",
    "ax.set_title(\"Distribution of the monthly case report\",size=15)\n",
    "ax.set_xlabel('Month')\n",
    "ax.set_ylabel('Number of case report')\n",
    "#ax.xaxis.set_major_locator(plt.MaxNLocator(30))\n",
    "plt.xticks(rotation=70)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Time between start of sickness and report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_diff_days(row):\n",
    "    if pd.isnull(row.DateIllnessStarted):\n",
    "        return np.nan\n",
    "    else: \n",
    "        return (row.dateofCaseReport - row.DateIllnessStarted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Referraltime'] = df[['DateIllnessStarted','dateofCaseReport']].apply(compute_diff_days, axis = 1 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Referraltime'] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum(df['Referraltime'].isna())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Referraltime'] .value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df['Referraltime'] == '-29 days']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have an odd value and we decide to drop it. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(index = 762, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dif_status = df.groupby(['Referraltime','FinalStatus']).numero.count().unstack(fill_value=0)\n",
    "df_dif_status.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(15,8))\n",
    "\n",
    "df_dif_status.plot(kind='bar',stacked=True, ax=ax, color = ['red', 'royalblue', 'brown'])\n",
    "\n",
    "plt.legend(loc=\"lower left\", bbox_to_anchor=(1,0))\n",
    "ax.set_title(\"Distirbution of the referral time\",size=14)\n",
    "ax.set_xlabel('Day waited to report')\n",
    "ax.set_ylabel('Number of individuals')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dif_exit = df.groupby(['Referraltime','TypeOfExit']).numero.count().unstack(fill_value=0)\n",
    "df_dif_exit.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(15,8))\n",
    "\n",
    "df_dif_exit.plot(kind='bar',stacked=True, ax=ax, color = ['red', 'royalblue', 'brown'])\n",
    "\n",
    "plt.legend(loc=\"lower left\", bbox_to_anchor=(1,0))\n",
    "ax.set_title(\"Distirbution of the referral time\",size=14)\n",
    "ax.set_xlabel('Day waited to report')\n",
    "ax.set_ylabel('Number of individuals')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### readmission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['readmission'].value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DelayBeforeAdmission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_delay_case = df.groupby(['DelayBeforeAdmission','FinalStatus']).numero.count().unstack(fill_value=0)\n",
    "df_delay_case.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(15,8))\n",
    "\n",
    "df_delay_case.plot(kind='bar',stacked=True, ax=ax, color = ['red', 'royalblue', 'brown'])\n",
    "\n",
    "plt.legend(loc=\"lower left\", bbox_to_anchor=(1,0))\n",
    "ax.set_title(\"Distirbution of the delay before admission\",size=14)\n",
    "ax.set_xlabel('Day delayed')\n",
    "ax.set_ylabel('Number of individuals')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['TypeOfExit'] = df['TypeOfExit'].str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_delay_exit = df.groupby(['DelayBeforeAdmission','TypeOfExit']).numero.count().unstack(fill_value=0)\n",
    "df_delay_exit.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(15,8))\n",
    "\n",
    "df_delay_exit.plot(kind='bar',stacked=True, ax=ax, color = ['green', 'red','royalblue', 'brown'])\n",
    "\n",
    "plt.legend(loc=\"lower left\", bbox_to_anchor=(1,0))\n",
    "ax.set_title(\"Distirbution of the delay before admission\",size=14)\n",
    "ax.set_xlabel('Day delayed')\n",
    "ax.set_ylabel('Number of individuals')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_delay_exit['Mortality rate'] = df_delay_exit.apply(lambda row : row['died'] / sum(row), axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(7,5))\n",
    "\n",
    "delay_mr = df_delay_exit.loc[:7,'Mortality rate']\n",
    "\n",
    "plt.scatter(delay_mr.index, delay_mr)\n",
    "ax.set_title(\"Mortality rate per delay before admission\",size=14)\n",
    "ax.set_xlabel('Day delayed')\n",
    "ax.set_ylabel('Mortality rate')\n",
    "ax.set_ylim(0, 1) \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TypeOfExit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum(df['TypeOfExit'].isna())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[df['TypeOfExit'].isna(), 'FinalStatus'].value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['TypeOfExit'] = df['TypeOfExit'].fillna('unknown')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['TypeOfExit'].value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FinalStatus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['FinalStatus'].value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(df.groupby(['FinalStatus','TypeOfExit']).numero.count())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LenghtOfStay "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum(df['LenghtOfStay'].isna())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_lstay_case = df.groupby(['LenghtOfStay','FinalStatus']).numero.count().unstack(fill_value=0)\n",
    "df_lstay_case.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(15,8))\n",
    "\n",
    "df_lstay_case.plot(kind='bar',stacked=True, ax=ax, color = ['red', 'royalblue', 'brown'])\n",
    "\n",
    "plt.legend(loc=\"lower left\", bbox_to_anchor=(1,0))\n",
    "ax.set_title(\"Distirbution of the length of stay\",size=14)\n",
    "ax.set_xlabel('Day stayed')\n",
    "ax.set_ylabel('Number of individuals')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_lstay_exit = df.groupby(['LenghtOfStay','TypeOfExit']).numero.count().unstack(fill_value=0)\n",
    "df_lstay_exit.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(15,8))\n",
    "\n",
    "df_lstay_exit.plot(kind='bar',stacked=True, ax=ax, color = ['green', 'red', 'brown', 'royalblue', 'yellow'])\n",
    "\n",
    "plt.legend(loc=\"lower left\", bbox_to_anchor=(1,0))\n",
    "ax.set_title(\"Distirbution of the length of stay\",size=14)\n",
    "ax.set_xlabel('Day stayed')\n",
    "ax.set_ylabel('Number of individuals')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['First'].value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_result = {'P' : 'Positive', 'N' : 'Negative', 'I' : 'Inconclusive', np.nan : 'Not done'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['First'] = df['First'].apply(lambda x: dict_result[x])\n",
    "df['Second'] = df['Second'].apply(lambda x: dict_result[x])\n",
    "df['Third'] = df['Third'].apply(lambda x: dict_result[x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tests_outcome = pd.DataFrame(df.groupby(['First','Second','Third', 'TypeOfExit','FinalStatus']).numero.count())\n",
    "df_tests_outcome"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MalariaTest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['MalariaTest'] = df['MalariaTest'].str.lower()\n",
    "df['MalariaTest'].value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_malaria = {'negative' : 'Negative', 'not done' : 'Unknown', 'positive' : 'Positive', \n",
    "                'n/a' : 'Unknown', 'no info' : 'Unknown', 'inconclusive' : 'Unknown', \n",
    "                'postive' : 'Positive', np.nan : 'Unknown'}\n",
    "\n",
    "df['MalariaTest'] = df['MalariaTest'].apply(lambda x: dict_malaria[x])\n",
    "df['MalariaTest'].value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(df.groupby(['MalariaTest', 'FinalStatus']).numero.count())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TypeOfExit "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['TypeOfExit'].value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Contact"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "contacts = ['Someone ill in the familiy','Visited someone ill','somebody recently died in your family','been to a funeral recently']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[:,contacts]=df.loc[:,contacts].fillna('N')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Someone ill in the familiy'].value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Visited someone ill'].value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['somebody recently died in your family'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['been to a funeral recently'].value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[:,contacts]=df.loc[:,contacts].applymap(lambda x: 1 if x == 'Y' else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Details of type of contact with FHF patient"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "details_contact = ['Yes/No', 'Slept in the same house', 'Had direct physical contact', 'Touched their body fluids', 'had sexual relations',  \n",
    "'Handled clothes or other personal objetc']              \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Symptoms since illness started"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "symptoms = ['fever', 'Vomit', 'Nausea', 'Diarrhoea', 'AstheniaWeakness', 'LossOfAppetite', 'AbdominalPain', 'ChestPain', \n",
    "'BoneMusclePain', 'JointPain','Headache', 'Cough', 'Breathlessness', 'SwallowingProblem',\n",
    "'Sorethroat', 'Jaundice', 'Conjunctivitis', 'HemoragicEyes','SkinRash', 'Hichups', 'PainEyesSensitivityLight',\n",
    "'Coma', 'ConfusedDisoriented', 'OtherHaemorraghe']\n",
    "\n",
    "infos = ['Sex', 'Age', 'Referraltime']\n",
    "tests = ['CT Values', 'MalariaTest']\n",
    "outputs = ['FinalStatus', 'TypeOfExit']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ml = df[infos+ symptoms + tests + outputs].copy()\n",
    "df_ml.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ml"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We drop the row that have only Nan values in the symptoms. (870 - 511)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ml.dropna(how='all', subset = symptoms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ml.dropna(how='all', subset = symptoms, inplace = True) \n",
    "df_ml[symptoms] = df_ml[symptoms].fillna('N')\n",
    "dict_binary_symptoms = {'Y' : 1, 'N' : 0}\n",
    "df_ml[symptoms] = df_ml[symptoms].applymap(lambda x: int(dict_binary_symptoms[x]))\n",
    "df_ml.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ml[symptoms+outputs].groupby(outputs).sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ML models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ml['Sex'] = df_ml['Sex'].apply(lambda x: 1 if x == 'M' else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ml['Referraltime'] = df_ml['Referraltime'].apply(lambda x: x.days)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Setting 1 Triage :** Using only the personnal informations and the symptoms. We want to find out if the patient has Ebola (FinalStatus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "#select the features needed\n",
    "df_triage = df_ml[infos+ symptoms+ ['FinalStatus']]\n",
    "df_triage = df_triage[(df_triage['FinalStatus'] != 'Probable') & ~(df_triage['FinalStatus'].isna())]\n",
    "\n",
    "#transform the dependent variable\n",
    "dict_fstatus = {'Confirmed' : 1, 'Not a Case' : 0}\n",
    "df_triage['FinalStatus'] = df_triage['FinalStatus'].apply(lambda x : dict_fstatus[x]) \n",
    "df_triage.dropna(how='any',inplace= True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_ebo_ml = df_triage.drop(columns=\"FinalStatus\")\n",
    "y_ebo_ml = df_triage['FinalStatus']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Corr_vision(X_ebo_ml)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Correlation with target label \n",
    "\n",
    "X_y = X_ebo_ml.join(y_ebo_ml)\n",
    "corr_matrix = X_y.corr()\n",
    "\n",
    "corr_y = corr_matrix['FinalStatus']\n",
    "threshold = 0.2\n",
    "fig, ax = plt.subplots(figsize=(10,6))\n",
    "corr_y[corr_y.index[abs(corr_y) > threshold].tolist()].drop('FinalStatus').plot(kind='barh')\n",
    "plt.title('Features that have an absolute pearson correlation value superior to {} with target variable'.format(threshold))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The values above are \"correlated\" with the output variable 'Finalstatus' (ebola outcome), we expect them to be considered important during the model.\n",
    "\n",
    "### Class imbalance\n",
    "\n",
    "Balance is important in order to get a reliable accuracy for unseen datas, if imbalanced, steps need to be taken in order to take this into account. \n",
    "A good metric to look at is precision, recall and F1, this is discussed in the report. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Imbalance(y_ebo_ml)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Rad_vision(X_ebo_ml, y_ebo_ml)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking at the figure above, we get no real difference between ebola negative and ebola positive patients."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PCA_vision_3D(X_ebo_ml, y_ebo_ml)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "k = 2 # Number of components\n",
    "pca = PCA(n_components = k)\n",
    "X_new = pca.fit_transform(X_ebo_ml)\n",
    "y_new = y_ebo_ml.copy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def myplot(X_new,y_new,coeff,labels=None):\n",
    "    xs = X_new[:,0]\n",
    "    ys = X_new[:,1]\n",
    "    n = coeff.shape[0]\n",
    "    cdict = {0: 'gray', 1: 'black'}\n",
    "    ldict = {0: 'Not a case', 1: 'Confirmed'}\n",
    "    fig, ax = plt.subplots()\n",
    "    for g in np.unique(y_new):\n",
    "        ix = np.where(y_new == g)\n",
    "        ax.scatter(xs[ix], ys[ix], c = cdict[g], label = ldict[g])\n",
    "    for i in range(n):\n",
    "        factor_ = 2.8\n",
    "        plt.arrow(0, 0, coeff[i,0]*factor_, coeff[i,1]*factor_,color = 'r',alpha = 0.5)\n",
    "        if labels is None and np.linalg.norm([coeff[i,0], coeff[i,1]])>0.9:\n",
    "            plt.text(coeff[i,0]* 2, coeff[i,1] * 2, str(X_ebo_ml.columns[i]), color = 'red', ha = 'center', va = 'center', fontsize=12, weight='bold')\n",
    "    \n",
    "    ax.legend()\n",
    "    plt.xlim(-2,2)\n",
    "    plt.ylim(-2,2)\n",
    "    plt.xlabel(\"PC{}\".format(1))\n",
    "    plt.ylabel(\"PC{}\".format(2))\n",
    "    plt.grid()\n",
    "    plt.show()\n",
    "    \n",
    "#Call the function. Use only the 2 PCs.\n",
    "myplot(X_new, y_new, np.transpose(pca.components_[0:2, :]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us apply PCA but dropping the sex, age and referraltime "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def myplot(X_new,y_new,coeff,labels=None):\n",
    "    xs = X_new[:,0]\n",
    "    ys = X_new[:,1]\n",
    "    n = coeff.shape[0]\n",
    "    cdict = {0: 'blue', 1: 'pink'}\n",
    "    ldict = {0: 'Not a case', 1: 'Confirmed'}\n",
    "    fig, ax = plt.subplots()\n",
    "    for g in np.unique(y_new):\n",
    "        ix = np.where(y_new == g)\n",
    "        ax.scatter(xs[ix], ys[ix], c = cdict[g], label = ldict[g])\n",
    "    for i in range(n):\n",
    "        factor_ = 2.8\n",
    "        plt.arrow(0, 0, coeff[i,0]*factor_, coeff[i,1]*factor_,color = 'r',alpha = 0.5)\n",
    "        if labels is None and np.linalg.norm([coeff[i,0], coeff[i,1]])>0.3:\n",
    "            plt.text(coeff[i,0]* 3, coeff[i,1] * 3, str(X_ebo_ml.columns[i]), color = 'black', ha = 'center', va = 'center', fontsize=12, weight='bold')\n",
    "    \n",
    "    ax.legend()\n",
    "    plt.xlim(-2,2)\n",
    "    plt.ylim(-2,2)\n",
    "    plt.xlabel(\"PC{}\".format(1))\n",
    "    plt.ylabel(\"PC{}\".format(2))\n",
    "    plt.grid()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_drop = X_ebo_ml.drop(columns=['Sex', 'Age', 'Referraltime'])\n",
    "\n",
    "# apply PCA \n",
    "k = 2\n",
    "pca = PCA(n_components = k)\n",
    "X_new = pca.fit_transform(X_drop)\n",
    "y_new = y_ebo_ml.copy()\n",
    "\n",
    "#Call the function. Use only the 2 PCs.\n",
    "myplot(X_new, y_new, np.transpose(pca.components_[0:2, :]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split train/test\n",
    "\n",
    "Before standardizing, we need to make sure that the dataset is split between train and test !\n",
    "This is to make sure that the \"way\" we standardize our train set is \"the base\" as to how we standardize our test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "X_ebo_train, X_ebo_test, y_ebo_train, y_ebo_test = train_test_split(X_ebo_ml, y_ebo_ml, test_size=0.2, random_state=0, stratify=y_ebo_ml)\n",
    "\n",
    "\n",
    "# Instantiate the visualizer\n",
    "visualizer = ClassBalance(labels=['Ebola Negative', 'Ebola Positive'])\n",
    "\n",
    "visualizer.fit(y_ebo_train, y_ebo_test)        # Fit the data to the visualizer\n",
    "visualizer.show()                      # Finalize and render the figure\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Normalizing the data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "numerical_col = ['Age','Referraltime']\n",
    "X_ebo_train.loc[:,numerical_col] = scaler.fit_transform(X_ebo_train[numerical_col])\n",
    "X_ebo_test.loc[:,numerical_col] = scaler.transform(X_ebo_test[numerical_col])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_triage[symptoms]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Least squares"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.api as sm\n",
    "\n",
    "X = sm.add_constant(df_triage.loc[:, df_triage.columns != 'FinalStatus'])\n",
    "y = df_triage['FinalStatus']\n",
    "#normalize the continuous variables\n",
    "scaler = StandardScaler()\n",
    "\n",
    "X[['Age','Referraltime']] = scaler.fit_transform(X[['Age','Referraltime']])\n",
    "\n",
    "# Model\n",
    "est_OLS = sm.OLS(y, X.astype(float)).fit()\n",
    "print(est_OLS.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "est_logit = sm.Logit(y, X.astype(float)).fit()\n",
    "print(est_logit.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see terrible r² values and we'll proceed to do some feature selection in order to improve the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Backward Elimination"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Feed all possible features to the model\n",
    "- Compute perfomance of model and remove worst perfoming features until stopping criterion\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### For Least square\n",
    "\n",
    "X = df_triage.loc[:, df_triage.columns != 'FinalStatus']\n",
    "y = df_triage['FinalStatus']\n",
    "tl\n",
    "#Backward Elimination\n",
    "cols = list(X.columns)\n",
    "pmax = 1\n",
    "while (len(cols)>0):\n",
    "    p= []\n",
    "    X_1 = X[cols]\n",
    "    X_1 = sm.add_constant(X_1)\n",
    "    model = sm.OLS(y,X_1).fit()\n",
    "    p = pd.Series(model.pvalues.values[1:],index = cols)      \n",
    "    pmax = max(p)\n",
    "    feature_with_p_max = p.idxmax()\n",
    "    if(pmax>0.05):\n",
    "        cols.remove(feature_with_p_max)\n",
    "    else:\n",
    "        break\n",
    "selected_features_BE = cols\n",
    "print(selected_features_BE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Assert the model with new features\n",
    "X = sm.add_constant(df_triage.loc[:, selected_features_BE])\n",
    "y = df_triage['FinalStatus']\n",
    "\n",
    "est_OLS = sm.OLS(y, X.astype(float)).fit()\n",
    "print(est_OLS.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic regression Backward elimation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_triage.loc[:, df_triage.columns != 'FinalStatus']\n",
    "y = df_triage['FinalStatus']\n",
    "\n",
    "#Backward Elimination\n",
    "cols = list(X.columns)\n",
    "pmax = 1\n",
    "while (len(cols)>0):\n",
    "    p= []\n",
    "    X_1 = X[cols]\n",
    "    X_1 = sm.add_constant(X_1)\n",
    "    model = sm.Logit(y,X_1).fit()\n",
    "    p = pd.Series(model.pvalues.values[1:],index = cols)      \n",
    "    pmax = max(p)\n",
    "    feature_with_p_max = p.idxmax()\n",
    "    if(pmax>0.05):\n",
    "        cols.remove(feature_with_p_max)\n",
    "    else:\n",
    "        break\n",
    "selected_features_BE = cols\n",
    "print(selected_features_BE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Update the model with the selected features \n",
    "X = sm.add_constant(df_triage.loc[:, selected_features_BE])\n",
    "y = df_triage['FinalStatus']\n",
    "\n",
    "est_Logit = sm.Logit(y, X.astype(float)).fit()\n",
    "print(est_Logit.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Pseudo-R^2 indicates that the model is not a good fit. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Recursive Feature Elimination\n",
    "The Recursive Feature Elimination (RFE) method works by recursively removing attributes and building a model on those attributes that remain. It uses accuracy metric to rank the feature according to their importance. The RFE method takes the model to be used and the number of required features as input. It then gives the ranking of all the variables, 1 being most important. It also gives its support, True being relevant feature and False being irrelevant feature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.feature_selection import RFE\n",
    "\n",
    "X = df_triage.loc[:, df_triage.columns != 'FinalStatus']\n",
    "y = df_triage['FinalStatus']\n",
    "\n",
    "#no of features \n",
    "nof_list=np.arange(1, len(X.columns)+1) \n",
    "\n",
    "highest_score=0\n",
    "#Variable to store the optimum features\n",
    "nof=0           \n",
    "score_list =[]\n",
    "for n in range(len(nof_list)):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X,y, test_size = 0.3, random_state = 0)\n",
    "    model = LinearRegression()\n",
    "    rfe = RFE(model,n_features_to_select=nof_list[n])\n",
    "    X_train_rfe = rfe.fit_transform(X_train,y_train)\n",
    "    X_test_rfe = rfe.transform(X_test)\n",
    "    model.fit(X_train_rfe,y_train)\n",
    "    #mean accuracy\n",
    "    score = model.score(X_test_rfe,y_test)\n",
    "    score_list.append(score)\n",
    "    if(score>highest_score):\n",
    "        highest_score = score\n",
    "        nof = nof_list[n]\n",
    "print(\"Optimum number of features: %d\" %nof)\n",
    "print(\"Score with %d features: %f\" % (nof, highest_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "X = df_triage.loc[:, df_triage.columns != 'FinalStatus']\n",
    "y = df_triage['FinalStatus']\n",
    "\n",
    "#no of features \n",
    "nof_list=np.arange(1, len(X.columns)+1)   \n",
    "\n",
    "highest_score=0\n",
    "#Variable to store the optimum features\n",
    "nof=0           \n",
    "score_list =[]\n",
    "for n in range(len(nof_list)):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X,y, test_size = 0.3, random_state = 0)\n",
    "    model = LogisticRegression(max_iter = 200)\n",
    "    rfe = RFE(model,n_features_to_select=nof_list[n])\n",
    "    X_train_rfe = rfe.fit_transform(X_train,y_train)\n",
    "    X_test_rfe = rfe.transform(X_test)\n",
    "    model.fit(X_train_rfe,y_train)\n",
    "    score = model.score(X_test_rfe,y_test)\n",
    "    score_list.append(score)\n",
    "    if(score>highest_score):\n",
    "        highest_score = score\n",
    "        nof = nof_list[n]\n",
    "print(\"Optimum number of features: %d\" %nof)\n",
    "print(\"Score with %d features: %f\" % (nof, highest_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## The RFE computed the number of features we should select (11)\n",
    "\n",
    "cols = np.array(X.columns)\n",
    "model = LogisticRegression(max_iter = 200)\n",
    "\n",
    "#Initializing RFE model\n",
    "rfe = RFE(model, n_features_to_select=11)   \n",
    "\n",
    "#Transforming data using RFE\n",
    "X_rfe = rfe.fit_transform(X,y)  \n",
    "\n",
    "#Fitting the data to model\n",
    "model.fit(X_rfe,y) \n",
    "print(\"R_squared: \" + str(model.score(X_rfe, y)))\n",
    "print(cols[rfe.support_])\n",
    "print(model.coef_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ensemble Methods\n",
    "Embedded methods are a catch-all group of techniques which perform feature selection as part of the model construction process. The exemplar of this approach is the LASSO method for constructing a linear model, which penalizes the regression coefficients with an L1 penalty, shrinking many of them to zero. Any features which have non-zero regression coefficients are 'selected' by the LASSO algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LassoCV\n",
    "X = df_triage.loc[:, df_triage.columns != 'FinalStatus']\n",
    "y = df_triage['FinalStatus']\n",
    "\n",
    "reg = LassoCV()\n",
    "reg.fit(X, y)\n",
    "\n",
    "print(\"Best alpha using built-in LassoCV: %f\" % reg.alpha_)\n",
    "print(\"Best score using built-in LassoCV: %f\" %reg.score(X,y))\n",
    "coef = pd.Series(reg.coef_, index = X.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Lasso picked \" + str(sum(coef != 0)) + \" variables and eliminated the other \" +  str(sum(coef == 0)) + \" variables\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imp_coef = coef.sort_values()\n",
    "import matplotlib\n",
    "matplotlib.rcParams['figure.figsize'] = (8.0, 10.0)\n",
    "imp_coef.plot(kind = \"barh\")\n",
    "plt.title(\"Feature importance using Lasso Model\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Let us try some more \"complex\" and easily interpretable models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Trees\n",
    "We did a few trees of varying depth. The problem is overfitting, which is fought with random forests. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import tree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### If you would like to export the following trees, replace the number preceeding the (denoted by '?') q by your interested tree. Where this number corresponds to the number of questions asked by the doctor \n",
    "\n",
    "\n",
    "from sklearn import tree\n",
    "import graphviz\n",
    "dot_data_?q = tree.export_graphviz(clf?q, \n",
    "                                out_file=None, \n",
    "                                feature_names=X.columns,\n",
    "                                rounded=True)\n",
    "graph_?q = graphviz.Source(dot_data_?q)\n",
    "graph_?q.render(\"Decision_tree_?_q\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### What happens when you only can ask one question ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "clf1q = tree.DecisionTreeClassifier(max_depth=1)\n",
    "clf1q = clf1q.fit(X_ebo_train, y_ebo_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score_model(X_ebo_train, y_ebo_train, X_ebo_test, y_ebo_test, clf1q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree.plot_tree(clf1q,feature_names=X.columns)\n",
    "fig = matplotlib.pyplot.gcf()\n",
    "\n",
    "fig.savefig('tree_1_question.png')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# What happens when you only can ask two question ?\n",
    "\n",
    "clf2q = tree.DecisionTreeClassifier(max_depth=2)\n",
    "clf2q = clf2q.fit(X_ebo_train, y_ebo_train)\n",
    "\n",
    "score_model(X_ebo_train, y_ebo_train, X_ebo_test, y_ebo_test, clf2q)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "tree.plot_tree(clf2q,feature_names=X.columns)\n",
    "fig = matplotlib.pyplot.gcf()\n",
    "fig.savefig('tree_2_question.png')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now with ten questions \n",
    "\n",
    "clf10q = tree.DecisionTreeClassifier(max_depth=10)\n",
    "clf10q = clf10q.fit(X_ebo_train, y_ebo_train)\n",
    "\n",
    "score_model(X_ebo_train, y_ebo_train, X_ebo_test, y_ebo_test, clf10q)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Decision trees are easy to overfit (refer to result just above), let's use Random forest and tune its hyper-parameters\n",
    "\n",
    "# Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import export_graphviz\n",
    "\n",
    "# What happens when you only can ask five question ?\n",
    "clf = RandomForestClassifier(n_estimators=10, max_depth=5, random_state = 123)\n",
    "\n",
    "clf = clf.fit(X_ebo_train, y_ebo_train)\n",
    "\n",
    "score_model(X_ebo_train, y_ebo_train, X_ebo_test, y_ebo_test, clf)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Hyper-parameter tuning "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "param_test = {\n",
    "    'n_estimators':[i for i in range(5, 20)],\n",
    "    'max_depth':[i for i in range(3, 15)],\n",
    "    'min_samples_split':[i for i in range(2, 7)]\n",
    "}\n",
    "clforest = RandomForestClassifier(random_state = 123)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "gsearch = GridSearchCV(\n",
    "    estimator= clforest,\n",
    "    param_grid= param_test,\n",
    "    scoring='roc_auc',\n",
    "    n_jobs=4,\n",
    "    iid=False,\n",
    "    cv=5\n",
    ")\n",
    "gsearch.fit(X_ebo_train, y_ebo_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gsearch.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "clf_best = RandomForestClassifier(n_estimators=19, max_depth=9, min_samples_split=4)\n",
    "\n",
    "clf_best = clf_best.fit(X_ebo_train, y_ebo_train)\n",
    "score_model(X_ebo_train, y_ebo_train, X_ebo_test, y_ebo_test, clf_best)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again great signs of overfitting \n",
    "\n",
    "Let us add a hyper-parameter which may help with the overfitting \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = {'n_estimators': [2,3,4,5,6], 'max_depth' : [3,4,5,6, 7, 8],\n",
    "              'min_samples_split': range(2,6), 'max_leaf_nodes': range(2,5)}\n",
    "\n",
    "ebo_forest_classifier = RandomForestClassifier()\n",
    "clf = GridSearchCV(ebo_forest_classifier, parameters, scoring = 'roc_auc', n_jobs=-1)\n",
    "clf.fit(X_ebo_train, y_ebo_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ebo_forest_classifier = RandomForestClassifier(n_estimators =clf.best_params_['n_estimators'],\n",
    "                                              max_depth = clf.best_params_['max_depth'],\n",
    "                                              min_samples_split = clf.best_params_['min_samples_split'],\n",
    "                                              max_leaf_nodes = clf.best_params_['max_leaf_nodes'])\n",
    "\n",
    "# Give score to model\n",
    "score_model(X_ebo_train, y_ebo_train, X_ebo_test, y_ebo_test, ebo_forest_classifier)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again, the model shows signs of overffing. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### This is to  output as a tree the random forest classifier\n",
    "\n",
    "\n",
    "dot_data_forest =export_graphviz(\n",
    "    ebo_forest_classifier.estimators_[1],\n",
    "    out_file=None,\n",
    "    feature_names=X.columns,\n",
    "    class_names=['Not a case', 'Confirmed'],\n",
    "    label='root',\n",
    "    filled=True,\n",
    "    rounded=True,\n",
    "    impurity=False,\n",
    "    proportion=True\n",
    ")\n",
    "graph_forest = graphviz.Source(dot_data_forest)\n",
    "graph_forest.render(\"Decision_forest_1\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XGBoost \n",
    "\n",
    "(eXtreme Gradient Boosting) : Advanced implementation of gradient boosting algorithm\n",
    "\n",
    "__Import libraries__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from xgboost.sklearn import XGBClassifier\n",
    "from sklearn.metrics import mean_squared_error as MSE \n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from matplotlib.pylab import rcParams\n",
    "from scipy import stats\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.inspection import permutation_importance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "##### __Hyperparameters__\n",
    "__BOOSTER PARAMETER__\n",
    "- _learning rate_:         eta = [[0,1]] (Use CV)\n",
    "- _min_child_weigt_:   (determines sum of weights of all weights required in a child) Controls overfitting, high values prevent models to learn from highly specific samples\n",
    "(Use CV)\n",
    "- _max_depth_: determines depth of tree [3-10] (Use CV)\n",
    "- _subsample_: % of samples used per tree, low value may lead to underfitting [0.5-1]\n",
    "- _colsample_bytree_: % features used per tree, high value, then overfitting [0.5-1]\n",
    "\n",
    "\n",
    "__Learning Task Parameters__\n",
    "- _objective_: (binary:logistic )logistic regression for binary classification, returns predicted probability (not class)\n",
    "- _eval_metric_= \"error\" Binary classification 0.5 threshold \n",
    "- _n_estimators_: number of trees to built\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "__To penalize__\n",
    "- _gamma_: The larger gamma is, the more conservative the algorithm will be. (loss required to split)\n",
    "- _alpha_: L1 regularization\n",
    "- _lambda_: L2 reg, smoother than L1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def modelfit(alg,x_train, y_train, x_test, y_test,useTrainCV=True, cv_folds=5, early_stopping_rounds=100):\n",
    "    \n",
    "    if useTrainCV:\n",
    "        xgb_param = alg.get_xgb_params()\n",
    "        xgtrain = xgb.DMatrix(x_train, y_train)\n",
    "        cvresult = xgb.cv(xgb_param, xgtrain, num_boost_round=alg.get_params()['n_estimators'], nfold=cv_folds,\n",
    "            metrics='auc', early_stopping_rounds=early_stopping_rounds,show_stdv=False)\n",
    "        alg.set_params(n_estimators=cvresult.shape[0])\n",
    "        print(cvresult.shape[0])\n",
    "    \n",
    "    #Fit the algorithm on the data\n",
    "    eval_set = [(x_train, y_train), (x_test, y_test)]\n",
    "    alg.fit(x_train, y_train,eval_metric='error', eval_set=eval_set, verbose=False)\n",
    "\n",
    "        \n",
    "    #Predict training set:\n",
    "    dtrain_predictions = alg.predict(x_train)\n",
    "    dtrain_predprob = alg.predict_proba(x_train)[:,1]\n",
    "        \n",
    "    #Print model report:\n",
    "    print(\"\\nModel Report\")\n",
    "    print(\"F1 accuracy score (train): \",metrics.f1_score(y_train,model.predict(x_train)))\n",
    "    print (\"Accuracy (train): %.3f\" %metrics.accuracy_score(y_train, dtrain_predictions))\n",
    "    print(\"Accuracy (test): %.3f\" %metrics.accuracy_score(y_test, alg.predict(x_test)))\n",
    "    print(\"F1 accuracy score (test): \",metrics.f1_score(y_test,model.predict(x_test)))\n",
    "    print(\"AUC Accuracy (train): %f\"%metrics.roc_auc_score(y_train, dtrain_predprob))\n",
    "    print(\"AUC Accuracy (test): %f\"%metrics.roc_auc_score(y_test, alg.predict_proba(x_test)[:,1]))\n",
    " \n",
    "    # Plot the important features\n",
    "    xgb.plot_importance(alg)\n",
    "\n",
    "    \n",
    "# Code inspired from : https://www.analyticsvidhya.com/blog/2016/03/complete-guide-parameter-tuning-xgboost-with-codes-python/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's try one by one parameter tuning\n",
    "\n",
    "General Approach for Parameter Tuning\n",
    "\n",
    "We will use an approach similar to that of GBM here. The various steps to be performed are:\n",
    "\n",
    "    Choose a relatively high learning rate. Generally a learning rate of 0.1 works but somewhere between 0.05 to 0.3 should work for different problems. Determine the optimum number of trees for this learning rate. XGBoost has a very useful function called as “cv” which performs cross-validation at each boosting iteration and thus returns the optimum number of trees required.\n",
    "    \n",
    "    Tune tree-specific parameters ( max_depth, min_child_weight, gamma, subsample, colsample_bytree) for decided learning rate and number of trees. Note that we can choose different parameters to define a tree and I’ll take up an example here.\n",
    "    \n",
    "    Tune regularization parameters (lambda, alpha) for xgboost which can help reduce model complexity and enhance performance.\n",
    "    Lower the learning rate and decide the optimal parameters .\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"This gives an idea of the scale_pos_weight value  \",sum(y_ebo_train==1)/sum(y_ebo_train==0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#############\n",
    "# tuning n_estimators (number of trees)\n",
    "#############\n",
    "\n",
    "model_tune = xgb.XGBClassifier(learning_rate =0.1,n_estimators=1000,max_depth=5,min_child_weight=1,\n",
    "                         gamma=0,subsample=0.8,colsample_bytree=0.8,objective= 'binary:logistic',\n",
    "                             nthread=4, seed=123, reg_lambda = 0,scale_pos_weight = 1.78)\n",
    "\n",
    "\n",
    "\n",
    "param_test1 = {'n_estimators':range(2,20,2)\n",
    "}\n",
    "gsearch1 = GridSearchCV(estimator = model_tune, \n",
    " param_grid = param_test1, scoring='roc_auc',n_jobs=4,iid=False, cv=5)\n",
    "gsearch1.fit(X_ebo_train,y_ebo_train)\n",
    "gsearch1.best_params_, gsearch1.best_score_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set parameters\n",
    "model_tune.set_params(n_estimators=gsearch1.best_params_['n_estimators'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### GridSearchCV\n",
    "\n",
    "Instead of looking at one parameter at a time, let us use GridSearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "################\n",
    "# Tune max_depth, et min_child weight\n",
    "################\n",
    "\n",
    "\n",
    "param_test1 = {'max_depth':range(3,10,2),'min_child_weight':range(1,6,2)\n",
    "}\n",
    "gsearch1 = GridSearchCV(estimator = \n",
    "                        model_tune, \n",
    "                                param_grid = param_test1, scoring='roc_auc',n_jobs=4,iid=False, cv=5)\n",
    "gsearch1.fit(X_ebo_train,y_ebo_train)\n",
    "gsearch1.best_params_, gsearch1.best_score_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# New optimal, let's set those instead \n",
    "model_tune.set_params(max_depth=gsearch1.best_params_['max_depth'],min_child_weight=gsearch1.best_params_['min_child_weight'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "################\n",
    "# Tune gamma\n",
    "################\n",
    "\n",
    "\n",
    "param_test3 = {\n",
    " 'gamma':[i/10.0 for i in range(0,10)]\n",
    "}\n",
    "gsearch3 = GridSearchCV(estimator = model_tune, \n",
    " param_grid = param_test3, scoring='roc_auc',n_jobs=4,iid=False, cv=5)\n",
    "gsearch3.fit(X_ebo_train,y_ebo_train)\n",
    "gsearch3.best_params_, gsearch3.best_score_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set gamma parameter\n",
    "model_tune.set_params(gamma=gsearch3.best_params_['gamma'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's have  a look at the model again \n",
    "modelfit(model_tune, X_ebo_train, y_ebo_train, X_ebo_test, y_ebo_test)\n",
    "score_model(X_ebo_train, y_ebo_train, X_ebo_test, y_ebo_test, model_tune)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "################\n",
    "# Tune subsample (% of sample used in trees) and colsample_bytree (% features used by trees)\n",
    "################\n",
    "\n",
    "param_test4 = {\n",
    " 'subsample':[i/10.0 for i in range(5,10)],\n",
    " 'colsample_bytree':[i/10.0 for i in range(5,10)]\n",
    "}\n",
    "gsearch4 = GridSearchCV(estimator =model_tune, \n",
    " param_grid = param_test4, scoring='roc_auc',n_jobs=4,iid=False, cv=5)\n",
    "gsearch4.fit(X_ebo_train,y_ebo_train)\n",
    "gsearch4.best_params_, gsearch4.best_score_\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's try smaller values around the ones found\n",
    "model_tune.set_params(subsample=gsearch4.best_params_['subsample'],colsample_bytree=gsearch4.best_params_['colsample_bytree'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_test5 = {\n",
    " 'subsample':[i/100.0 for i in range(70,80,5)],\n",
    " 'colsample_bytree':[i/100.0 for i in range(65,80,5)]\n",
    "}\n",
    "gsearch5 = GridSearchCV(estimator = model_tune, \n",
    " param_grid = param_test5, scoring='roc_auc',n_jobs=4,iid=False, cv=5)\n",
    "gsearch5.fit(X_ebo_train,y_ebo_train)\n",
    "gsearch5.best_params_, gsearch5.best_score_\n",
    "\n",
    "# It changed a little, we pick these instead"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set new parameters \"optimal parameters\"\n",
    "model_tune.set_params(subsample=gsearch5.best_params_['subsample'],colsample_bytree=gsearch5.best_params_['colsample_bytree'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "################\n",
    "# reg_lambda: L2 reg tuning\n",
    "################\n",
    "\n",
    "\n",
    "param_test6 = {\n",
    " 'reg_lambda':[1e-5, 1e-2, 0.1, 1, 100]\n",
    "}\n",
    "gsearch6 = GridSearchCV(estimator = model_tune, \n",
    " param_grid = param_test6, scoring='roc_auc',n_jobs=4,iid=False, cv=5)\n",
    "\n",
    "gsearch6.fit(X_ebo_train,y_ebo_train)\n",
    "gsearch6.best_params_, gsearch6.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's try tigher values around the one found\n",
    "\n",
    "param_test7 = {\n",
    " 'reg_lambda': np.arange(0,1,0.01)\n",
    "}\n",
    "gsearch7 = GridSearchCV(estimator = model_tune, \n",
    " param_grid = param_test7, scoring='roc_auc',n_jobs=4,iid=False, cv=5)\n",
    "\n",
    "gsearch7.fit(X_ebo_train,y_ebo_train)\n",
    "gsearch7.best_params_, gsearch7.best_score_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_tune.set_params(reg_lambda=gsearch7.best_params_['reg_lambda'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score_model(X_ebo_train, y_ebo_train, X_ebo_test, y_ebo_test, model_tune)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Last step is the learning rate\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "param_test8 = {\n",
    " 'learning_rate': np.arange(0.01,0.3,0.01)\n",
    "}\n",
    "gsearch8 = GridSearchCV(estimator = model_tune, \n",
    " param_grid = param_test8, scoring='roc_auc',n_jobs=4,iid=False, cv=5)\n",
    "\n",
    "gsearch8.fit(X_ebo_train,y_ebo_train)\n",
    "gsearch8.best_params_, gsearch8.best_score_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the new learning rate (final parameter)\n",
    "model_tune.set_params(learning_rate=gsearch8.best_params_['learning_rate'])\n",
    "\n",
    "# Final model\n",
    "\n",
    "score_model(X_ebo_train, y_ebo_train, X_ebo_test, y_ebo_test, model_tune)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Instead of cross validating, one or two parameters at a time, let's do many \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "param_test = {'learning_rate': np.arange(0.01,0.3,0.1), 'n_estimators':np.arange(9,20,5),'max_depth':[2,3,4], 'gamma': [i/10.0 for i in range(0,3)],\n",
    "               'min_child_weight':np.arange(5,8,1),'subsample': [i/100.0 for i in range(70,80,5)], 'colsample_bytree': [i/100.0 for i in range(65,80,5)], \n",
    "                  'reg_lambda':np.arange(0,7,1)}\n",
    "\n",
    "gsearch = GridSearchCV(estimator = \n",
    "                        XGBClassifier(learning_rate =0.1,n_estimators=1000,max_depth=5,min_child_weight=1,\n",
    "                         gamma=0,subsample=0.8,colsample_bytree=0.8,objective= 'binary:logistic',\n",
    "                             nthread=4, seed=123, reg_lambda = 0,scale_pos_weight = 1.78), \n",
    "                                param_grid = param_test, scoring='roc_auc',n_jobs=4,iid=False, cv=5,verbose = False)\n",
    "gsearch.fit(X_ebo_train,y_ebo_train)\n",
    "gsearch.best_params_, gsearch.best_score_\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model with optimized set of parameters \n",
    "model_CV = XGBClassifier( learning_rate =0.11, n_estimators=19, max_depth=3,\n",
    "                         min_child_weight=5, gamma=0.1, subsample=0.75, colsample_bytree=0.7,\n",
    "                         objective= 'binary:logistic', nthread=4, scale_pos_weight=1.78, reg_lambda = 2,seed=123)\n",
    "\n",
    "# Model report with CV\n",
    "#modelfit(model_CV, x_train, y_train, x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score_model(X_ebo_train, y_ebo_train, X_ebo_test, y_ebo_test, model_CV)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cumulator.off() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cumulator.computation_costs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
